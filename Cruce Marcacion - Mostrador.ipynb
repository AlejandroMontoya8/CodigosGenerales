{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "789e95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e63372",
   "metadata": {},
   "source": [
    "### Unión fuentes proveedores Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cf752760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MU = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\MUSemanal.xlsx\")\n",
    "usuarios_MU = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Puntos MU.xlsx\")\n",
    "df_MU=df_MU[[\"uuid\",\"num_orden\",\"fecha_inicio\",\"valor_total_servicio\",\"tipo_pago\",\"cant_paradas\",\"distancia_km\",\"estado_servicio\",\"descripcion\",\"iniciado\",\"asignado\",\"llego_punto\",\"salio_punto\",\"llego_cliente\",\"finalizado\",\"entrega_fallida\",\"tipificación_fallida\",\"nombre_solicitante\"]]\n",
    "\n",
    "df_MU['iniciado'] = pd.to_datetime(df_MU.iniciado).dt.tz_localize(None)\n",
    "df_MU['asignado'] = pd.to_datetime(df_MU.asignado).dt.tz_localize(None)\n",
    "df_MU['llego_punto'] = pd.to_datetime(df_MU.llego_punto).dt.tz_localize(None)\n",
    "df_MU['salio_punto'] = pd.to_datetime(df_MU.salio_punto).dt.tz_localize(None)\n",
    "df_MU['llego_cliente'] = pd.to_datetime(df_MU.llego_cliente).dt.tz_localize(None)\n",
    "df_MU['finalizado'] = pd.to_datetime(df_MU.finalizado).dt.tz_localize(None)\n",
    "\n",
    "    \n",
    "df_MU[\"iniciado\"] = pd.to_datetime(df_MU[\"iniciado\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_MU[\"asignado\"] = pd.to_datetime(df_MU[\"asignado\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_MU[\"llego_punto\"] = pd.to_datetime(df_MU[\"llego_punto\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_MU[\"salio_punto\"] = pd.to_datetime(df_MU[\"salio_punto\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_MU[\"llego_cliente\"] = pd.to_datetime(df_MU[\"llego_cliente\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_MU[\"finalizado\"] = pd.to_datetime(df_MU[\"finalizado\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "df_MU[\"Proveedor\"] = \"MU\"\n",
    "\n",
    "df_MU = pd.merge(df_MU,usuarios_MU,left_on='nombre_solicitante',right_on='nombre_solicitante',how = 'left')\n",
    "df_MU[\"Marcacion\"] = \" \"\n",
    "df_MU[\"Id_origen\"] = \" \"\n",
    "\n",
    "fechas_inicioMU = df_MU[\"fecha_inicio\"]\n",
    "nuevas_fechas = []\n",
    "\n",
    "for elemento in fechas_inicioMU:\n",
    "    elemento = elemento[0:10]\n",
    "    nuevas_fechas.append(elemento)\n",
    "\n",
    "df_MU[\"fecha_inicio\"] = nuevas_fechas\n",
    "\n",
    "df_MU[\"fecha_inicio\"] = pd.to_datetime(df_MU[\"fecha_inicio\"],format = \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "df_MU  = df_MU.reindex(columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','entrega_fallida','tipificación_fallida','descripcion','iniciado', 'asignado', 'llego_punto', 'salio_punto','llego_cliente', 'finalizado','num_orden','tipo_pago','Id_origen','Marcacion','valor_total_servicio','Cod','Proveedor','estado_servicio'])\n",
    "df_MU.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']\n",
    "\n",
    "df_MU.loc[df_MU[\"Finalizado_Fallido\"]==\"Sí\",\"Finalizado_Fallido\"] = \"Si\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95300349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\562936005.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  QuickGo_parcial = pd.read_csv(nombre_archivo,sep = \";\")\n"
     ]
    }
   ],
   "source": [
    "df_QuickGo = pd.DataFrame(columns = ['ID Servicio','Total (Km)','Precio Total','Número de orden','Fecha de solicitud','Fecha de creación','Email','Cantidad Paradas','Estado','Fecha Hora Asignado','Fecha Hora Llegada Primera Parada','Fecha Hora Salida Primera Parada','Fecha Hora Llegada Segunda Parada','Fecha Hora Finalizacion Servicio','Tipo de Novedad'])\n",
    "for the_file in os.listdir(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Quick Go\"):\n",
    "    nombre_archivo = os.path.join(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Quick Go\",the_file)\n",
    "    QuickGo_parcial = pd.read_csv(nombre_archivo,sep = \";\")\n",
    "    QuickGo_parcial = QuickGo_parcial[['ID Servicio','Total (Km)','Precio Total','Número de orden','Fecha de solicitud','Fecha de creación','Email','Cantidad Paradas','Estado','Fecha Hora Asignado','Fecha Hora Llegada Primera Parada','Fecha Hora Salida Primera Parada','Fecha Hora Llegada Segunda Parada','Fecha Hora Finalizacion Servicio','Tipo de Novedad']]\n",
    "    df_QuickGo = pd.concat([df_QuickGo,QuickGo_parcial],axis  = 0)\n",
    "\n",
    "df_QuickGo.columns = ['ID_Servicio','Total_(Km)','Precio_Total','Número_orden','fecha_solicitud','fecha_creacion','Email','Cantidad_Paradas','Estado','fecha_asignado','llegada_punto','salida_punto','llegada_cliente','fecha_finalizado','Tipo_Novedad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "71e5fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QuickGo['fecha_solicitud'] = pd.to_datetime(df_QuickGo['fecha_solicitud'],format=\"%d/%m/%Y %H:%M:%S\")\n",
    "df_QuickGo['fecha_asignado'] = pd.to_datetime(df_QuickGo['fecha_asignado'],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_QuickGo['llegada_punto'] = pd.to_datetime(df_QuickGo['llegada_punto'],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_QuickGo['salida_punto'] = pd.to_datetime(df_QuickGo['salida_punto'],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_QuickGo['llegada_cliente'] = pd.to_datetime(df_QuickGo['llegada_cliente'],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_QuickGo['fecha_finalizado'] = pd.to_datetime(df_QuickGo['fecha_finalizado'],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "df_QuickGo['fecha_solicitud'] = pd.to_datetime(df_QuickGo.fecha_solicitud).dt.tz_localize(None)\n",
    "df_QuickGo['fecha_asignado'] = pd.to_datetime(df_QuickGo.fecha_asignado).dt.tz_localize(None)\n",
    "df_QuickGo['llegada_punto'] = pd.to_datetime(df_QuickGo.llegada_punto).dt.tz_localize(None)     \n",
    "df_QuickGo['salida_punto'] = pd.to_datetime(df_QuickGo.salida_punto).dt.tz_localize(None)\n",
    "df_QuickGo['llegada_cliente'] = pd.to_datetime(df_QuickGo.llegada_cliente).dt.tz_localize(None) \n",
    "df_QuickGo['fecha_finalizado'] = pd.to_datetime(df_QuickGo.fecha_finalizado).dt.tz_localize(None) \n",
    "\n",
    "df_QuickGo[\"Proveedor\"] = \"Quick Go\"\n",
    "df_QuickGo [\"Marcacion\"] = \" \"\n",
    "df_QuickGo[\"Id_origen\"] = \" \"\n",
    "df_QuickGo[\"descripcion\"] = \" \"\n",
    "df_QuickGo[\"tipo_pago\"] = np.nan\n",
    "\n",
    "fechas_creacionGo = df_QuickGo[\"fecha_creacion\"]\n",
    "nuevas_fechas = []\n",
    "\n",
    "for elemento in fechas_creacionGo:\n",
    "    elemento = elemento[0:10]\n",
    "    nuevas_fechas.append(elemento)\n",
    "\n",
    "df_QuickGo[\"fecha_creacion\"] = nuevas_fechas\n",
    "df_QuickGo[\"fecha_creacion\"] = pd.to_datetime(df_QuickGo[\"fecha_creacion\"],format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "df_QuickGo[\"Finalizado_Fallido\"] = \"Si\"\n",
    "df_QuickGo.loc[df_QuickGo.Tipo_Novedad.isnull(),\"Finalizado_Fallido\"] = \"No\"   \n",
    "\n",
    "usuarios_Go =df_QuickGo[\"Email\"]\n",
    "Id_solicitante = []\n",
    "for elemento in usuarios_Go:\n",
    "    elemento = elemento[elemento.find('.') + 1:elemento.find('@')]\n",
    "    Id_solicitante.append(elemento)\n",
    "\n",
    "df_QuickGo[\"Id_solicitante\"] = Id_solicitante\n",
    "\n",
    "df_QuickGo = df_QuickGo.drop(['Email'],axis=1)\n",
    "\n",
    "df_QuickGo = df_QuickGo.reindex(columns=['ID_Servicio','fecha_creacion','Cantidad_Paradas','Total_(Km)','Finalizado_Fallido','Tipo_Novedad','descripcion','fecha_solicitud','fecha_asignado','llegada_punto','salida_punto','llegada_cliente','fecha_finalizado','Número_orden','tipo_pago','Id_origen','Marcacion','Precio_Total','Id_solicitante','Proveedor','Estado'])\n",
    "df_QuickGo.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9d3d8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QuickHelp = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\QuickHelpSemanal.xlsx\")\n",
    "df_QuickHelp=df_QuickHelp[['estado', 'entrega','fecha_entrega','usuario_creador','fecha_creacion','fecha_aceptacion','fecha_llegada','fecha_cierre','tipo_servicio','factura_cv']]\n",
    "df_QuickHelp[\"Finalizado_Fallido\"] = \"No\"\n",
    "df_QuickHelp[\"Tipo_Novedad\"] = np.nan\n",
    "df_QuickHelp[\"Cant_paradas\"] = np.nan\n",
    "df_QuickHelp[\"Total_(km)\"] =np.nan\n",
    "df_QuickHelp[\"llegada_punto\"] =np.nan\n",
    "df_QuickHelp[\"llegada_punto\"] = pd.to_datetime(df_QuickHelp[\"llegada_punto\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_QuickHelp[\"salida_punto\"] = np.nan\n",
    "df_QuickHelp[\"salida_punto\"] = pd.to_datetime(df_QuickHelp[\"salida_punto\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_QuickHelp[\"tipo_pago\"] = np.nan\n",
    "df_QuickHelp[\"Id_origen\"] = \" \"\n",
    "df_QuickHelp[\"Marcacion\"] = \" \"\n",
    "df_QuickHelp[\"Precio_total\"] = np.nan\n",
    "df_QuickHelp[\"Proveedor\"] = \"Quick Help\"\n",
    "\n",
    "usuarios_Help = df_QuickHelp[\"usuario_creador\"]\n",
    "Id_solicitante = []\n",
    "for elemento in usuarios_Help:\n",
    "    elemento = elemento[elemento.find('.') + 1 : elemento.find('@')]\n",
    "    Id_solicitante.append(elemento)\n",
    "\n",
    "df_QuickHelp[\"Id_solicitante\"] = Id_solicitante\n",
    "\n",
    "df_QuickHelp = df_QuickHelp.reindex(columns = ['entrega','fecha_entrega','Cant_paradas','Total_(km)','Finalizado_Fallido','Tipo_Novedad','tipo_servicio','fecha_creacion','fecha_aceptacion','llegada_punto','salida_punto','fecha_llegada','fecha_cierre','factura_cv','tipo_pago','Id_origen','Marcacion','Precio_total','Id_solicitante','Proveedor','estado'])\n",
    "df_QuickHelp.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ba65901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pibox = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\PiboxSemanal.xlsx\")\n",
    "usuarios_Pibox = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Puntos Pibox.xlsx\")\n",
    "df_Pibox=df_Pibox[['UUID','Orden Parada','Fecha Inicio','Distancia (Km)','Estado','Finalizado Fallido','Descripción Servicio Fallido','Iniciado','Asignado','Llegó al Origen','Salió de Origen','Llegó donde el Cliente','Finalizó Servicio','Num. Orden','Nombre Usuario','Valor Total Servicio']]\n",
    "df_Pibox[\"tipo_pago\"] = np.nan\n",
    "df_Pibox[\"Id_origen\"] = \" \"\n",
    "df_Pibox[\"Marcacion\"] = \" \"\n",
    "df_Pibox[\"descripcion\"] = \" \"\n",
    "df_Pibox[\"Proveedor\"] = \"Pibox\"\n",
    "\n",
    "df_Pibox = pd.merge(df_Pibox,usuarios_Pibox,left_on='Nombre Usuario',right_on='Nombre Usuario',how='left')\n",
    "\n",
    "df_Pibox = df_Pibox.reindex(columns = ['UUID','Fecha Inicio','Orden Parada','Distancia (Km)','Finalizado Fallido','Descripción Servicio Fallido','descripcion','Iniciado','Asignado','Llegó al Origen','Salió de Origen','Llegó donde el Cliente','Finalizó Servicio','Num. Orden','tipo_pago','Id_origen','Marcacion','Valor Total Servicio','Cod','Proveedor','Estado'])\n",
    "df_Pibox.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']                          \n",
    "\n",
    "ordenes = df_Pibox[\"numorden\"]\n",
    "numorden_pibox_2 = []\n",
    "for element in ordenes:\n",
    "    element = element.replace('PEDIDO ','')\n",
    "    numorden_pibox_2.append(element)\n",
    "\n",
    "df_Pibox['numorden'] = numorden_pibox_2\n",
    "\n",
    "df_Pibox.loc[df_Pibox[\"Estado\"]==\"Expirado\",\"Estado\"] =\"Cancelado\"\n",
    "\n",
    "distancias = df_Pibox[\"distancia_km\"]\n",
    "distancias_nuevo = []\n",
    "for elemento in distancias: \n",
    "    elemento = elemento[0:elemento.find(\",\")]\n",
    "    distancias_nuevo.append(elemento)\n",
    "df_Pibox[\"distancia_km\"] = distancias_nuevo\n",
    "df_Pibox[\"distancia_km\"] = pd.to_numeric(df_Pibox[\"distancia_km\"],downcast =\"integer\")\n",
    "\n",
    "df_Pibox[\"Valor_con_Descuentos\"] = df_Pibox[\"Valor_con_Descuentos\"].fillna(\"$\")\n",
    "plata = df_Pibox[\"Valor_con_Descuentos\"]\n",
    "plata2 = []\n",
    "for registro in plata:\n",
    "    valorn = registro.replace(\"$\",\"\")\n",
    "    valorn = valorn.replace(\".\",\"\")\n",
    "    \n",
    "    plata2.append(valorn)\n",
    "    \n",
    "df_Pibox[\"Valor_con_Descuentos\"] = plata2\n",
    "df_Pibox[\"Valor_con_Descuentos\"] = pd.to_numeric(df_Pibox[\"Valor_con_Descuentos\"],downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9a851566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = resultado\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = pd.to_datetime(d_frame[\"fecha_origen\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = resultado\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = pd.to_datetime(d_frame[\"fecha_origen\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:21: FutureWarning: Passing 'suffixes' which cause duplicate columns {'fecha_origen_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_Oficios = pd.merge(df_Oficios,d_frame,left_on=\"Service\",right_on=\"Service\",how=\"left\")\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = resultado\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = pd.to_datetime(d_frame[\"fecha_origen\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = resultado\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_frame[\"fecha_origen\"] = pd.to_datetime(d_frame[\"fecha_origen\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1263532801.py:21: FutureWarning: Passing 'suffixes' which cause duplicate columns {'fecha_origen_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_Oficios = pd.merge(df_Oficios,d_frame,left_on=\"Service\",right_on=\"Service\",how=\"left\")\n"
     ]
    }
   ],
   "source": [
    "df_Oficios = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\OficiosSemanal.xlsx\")\n",
    "usuarios_Oficios = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Puntos Oficios.xlsx\")\n",
    "df_Oficios=df_Oficios[['Service','Fecha Servicio','Status','Km','# Paradas','Valor total servicio','Hs-en espera','Hs-asignado','Hs-Llegando/origen','Hs-saliendo/origen','Hs-llegando/destino','Hs-Finalizado','id-Cliente','Convenio','Punto','Origen']]\n",
    "df_Oficios.columns =['Service','fecha_servicio','Status','Km','Paradas','Valor_servicio','en_espera','asignado','Llegando_origen','saliendo_origen','llegando_destino','Finalizado','id_cliente','Convenio','Punto','Origen']\n",
    "\n",
    "def recorte_fecha(d_frame,df_Oficios):\n",
    "    \n",
    "    d_frame.columns = ['Service','fecha_origen']\n",
    "    d_frame = d_frame[~d_frame.fecha_origen.isnull()]\n",
    "    lista = d_frame[\"fecha_origen\"]\n",
    "    cant_columns = len(df_Oficios.columns)\n",
    "    \n",
    "    resultado = []\n",
    "    for elemento in lista:\n",
    "        elemento = elemento[0:20]\n",
    "        resultado.append(elemento)\n",
    "    \n",
    "    d_frame[\"fecha_origen\"] = resultado\n",
    "    d_frame[\"fecha_origen\"] = pd.to_datetime(d_frame[\"fecha_origen\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "    \n",
    "    df_Oficios = pd.merge(df_Oficios,d_frame,left_on=\"Service\",right_on=\"Service\",how=\"left\")\n",
    "    \n",
    "    \n",
    "    return df_Oficios\n",
    "\n",
    "fechas = ['en_espera','asignado','Llegando_origen','saliendo_origen','llegando_destino','Finalizado']\n",
    "\n",
    "for reg in fechas:   \n",
    "    df_Oficios_fechas  = df_Oficios[['Service',reg]]    \n",
    "    df_Oficios = recorte_fecha(df_Oficios_fechas,df_Oficios)\n",
    "\n",
    "\n",
    "df_Oficios.columns= ['Service','fecha_servicio', 'Status', 'Km', 'Paradas', 'Valor_servicio', 'en_espera',\n",
    "       'asignado', 'Llegando_origen', 'saliendo_origen', 'llegando_destino',\n",
    "       'Finalizado', 'id_cliente', 'Convenio', 'Punto', 'Origen',\n",
    "       'en_espera(2)', 'asignado(2)', 'llegando_origen(2)', 'saliendo_origen(2)',\n",
    "       'llegando_destino(2)', 'finalizado(2)']\n",
    "\n",
    "df_Oficios = df_Oficios[['Service','fecha_servicio', 'Status', 'Km', 'Paradas', 'Valor_servicio','id_cliente', 'Convenio', 'Punto', 'Origen',\n",
    "       'en_espera(2)', 'asignado(2)', 'llegando_origen(2)', 'saliendo_origen(2)',\n",
    "       'llegando_destino(2)', 'finalizado(2)']]\n",
    "\n",
    "fechas_oficios = df_Oficios[\"fecha_servicio\"]\n",
    "fechas_of_nuevas = []\n",
    "\n",
    "for elemento in fechas_oficios:\n",
    "    elemento = elemento[0:10]\n",
    "    fechas_of_nuevas.append(elemento)\n",
    "\n",
    "df_Oficios[\"fecha_servicio\"] = fechas_of_nuevas\n",
    "df_Oficios[\"fecha_servicio\"] = pd.to_datetime(df_Oficios[\"fecha_servicio\"],format=\"%Y-%m-%d\")\n",
    "\n",
    "df_Oficios[\"tipo_pago\"] = np.nan\n",
    "df_Oficios[\"Id_origen\"] = \" \"\n",
    "df_Oficios[\"Marcacion\"] = \" \"\n",
    "df_Oficios[\"Proveedor\"] =\"Oficios\"\n",
    "df_Oficios[\"Finalizado Fallido\"] = \"No\"\n",
    "df_Oficios[\"Tipo_Novedad\"] = np.nan\n",
    "\n",
    "df_Oficios=pd.merge(df_Oficios,usuarios_Oficios,left_on='Punto',right_on='Punto',how='left')\n",
    "\n",
    "    \n",
    "df_Oficios = df_Oficios.reindex(columns = ['Service','fecha_servicio','Paradas','Km','Finalizado Fallido','Tipo_Novedad','Convenio','en_espera(2)', 'asignado(2)', 'llegando_origen(2)', 'saliendo_origen(2)','llegando_destino(2)', 'finalizado(2)','id_cliente','tipo_pago','Id_origen','Marcacion','Valor_servicio','Cod','Proveedor','Status'])\n",
    "df_Oficios.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "103bf430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Servicourier = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\ServicourierSemanal.xlsx\")\n",
    "df_Servicourier =df_Servicourier[[' Id ',' Pedido ',' Zona ',' ModoPago ',' Estado ',' EntDom ',' EntCliente ',' KMS ']]\n",
    "df_Servicourier.columns = ['Id','Pedido','Zona','ModoPago','Estado','EntDom','EntCliente','KMS']\n",
    "df_Servicourier = df_Servicourier[~df_Servicourier.Zona.isnull()]\n",
    "\n",
    "df_Servicourier[\"Finalizado_Fallido\"] = \"No\"\n",
    "df_Servicourier[\"Tipo_Novedad\"] = np.nan\n",
    "df_Servicourier[\"descripcion\"] = \" \"\n",
    "df_Servicourier[\"Cant_paradas\"] = np.nan\n",
    "df_Servicourier[\"llegada_punto\"] =np.nan\n",
    "df_Servicourier[\"llegada_punto\"] = pd.to_datetime(df_Servicourier[\"llegada_punto\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_Servicourier[\"salida_punto\"] = np.nan\n",
    "df_Servicourier[\"salida_punto\"] = pd.to_datetime(df_Servicourier[\"salida_punto\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_Servicourier[\"asignacion\"] = np.nan\n",
    "df_Servicourier[\"asignacion\"] = pd.to_datetime(df_Servicourier[\"asignacion\"],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "df_Servicourier[\"finalizado\"] = df_Servicourier[\"EntCliente\"]\n",
    "df_Servicourier[\"Id_origen\"] = \" \"\n",
    "df_Servicourier[\"Marcacion\"] = \" \"\n",
    "df_Servicourier[\"Precio_total\"] = np.nan\n",
    "df_Servicourier[\"Proveedor\"] = \"Servicourier\"\n",
    "\n",
    "solicitantes_Servicourier=df_Servicourier[\"Zona\"]\n",
    "Id_solicitante = []\n",
    "for elemento in solicitantes_Servicourier:\n",
    "    elemento = elemento[0:3]\n",
    "    Id_solicitante.append(elemento)\n",
    "    \n",
    "df_Servicourier[\"Id_solicitante\"] = Id_solicitante\n",
    "\n",
    "fechas_convertir = df_Servicourier[\"EntDom\"]\n",
    "\n",
    "fecha_servicio =[]\n",
    "\n",
    "for dato in fechas_convertir:\n",
    "    dato=dato.strftime(\"%Y-%m-%d\")\n",
    "    fecha_servicio.append(dato)\n",
    "    \n",
    "df_Servicourier[\"fecha_servicio\"]=fecha_servicio\n",
    "df_Servicourier[\"fecha_servicio\"] = pd.to_datetime(df_Servicourier[\"fecha_servicio\"],format=\"%Y-%m-%d\")\n",
    "\n",
    "df_Servicourier = df_Servicourier[['Id', 'Pedido', 'ModoPago', 'Estado', 'EntDom', 'EntCliente','KMS', 'Finalizado_Fallido', 'Tipo_Novedad', 'Cant_paradas','llegada_punto', 'salida_punto', 'asignacion', 'finalizado','Id_origen', 'Marcacion', 'Precio_total', 'Proveedor', 'Id_solicitante','fecha_servicio']]\n",
    "df_Servicourier = df_Servicourier.reindex(columns=['Id','fecha_servicio','Cant_paradas','KMS','Finalizado_Fallido','Tipo_Novedad','descripcion','EntDom','asignacion','llegada_punto','salida_punto','EntCliente','finalizado','Pedido','ModoPago','Id_origen','Marcacion','Precio_total','Id_solicitante','Proveedor','Estado'])\n",
    "df_Servicourier.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']                          \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1f353b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Total = pd.concat([df_MU,df_QuickGo,df_QuickHelp,df_Pibox,df_Oficios,df_Servicourier],axis=0)\n",
    "#df_Total[\"distancia_km\"] = pd.to_numeric(df_Total[\"distancia_km\"],downcast=\"float\")\n",
    "#df_Total[\"Valor_con_Descuentos\"] = pd.to_numeric(df_Total[\"Valor_con_Descuentos\"],downcast = \"float\")\n",
    "estados_traza = [\"CANCELACION\",\"Cancelado\",\"CERRADO CON NOVEDAD\",\"Devuelta\",\"Devuelto\",\"ENTREGADO\",\"Exitosa\",\"Finalizado\"]\n",
    "df_Total = df_Total[df_Total.Estado.isin(estados_traza)]\n",
    "df_Total = df_Total.loc[~((df_Total[\"descripcion\"].str.contains(\"Disp[a-z]*\")) |(df_Total[\"descripcion\"].str.contains(\"disp[a-z]*\")) | (df_Total[\"descripcion\"].str.contains(\"DISP[a-z]*\")))]\n",
    "df_Total = df_Total[~df_Total.ID_Solicitante.isnull()]\n",
    "df_Total = df_Total[df_Total[\"ID_Solicitante\"]!=\"cardenas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8051c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(\n",
    "    host=\"172.18.50.9\",\n",
    "    port=3306,\n",
    "    user=\"consultapedidos\",\n",
    "    password=\"#Cr9zV3rd3*\",\n",
    "    db=\"domicilios\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1f095162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 402 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "periodo = 202212\n",
    "\n",
    "cur = cnx.cursor()\n",
    "cur.execute(\"SELECT pedido, local_n, periodo FROM domi_pedidos WHERE domi_pedidos.periodo >= %s\", (periodo,))\n",
    "\n",
    "data =cur.fetchall()\n",
    "Domifacil = pd.DataFrame(data)\n",
    "Domifacil.columns = cur.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5eb32c",
   "metadata": {},
   "source": [
    "### Cruces Marcación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e05df020",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes_convert =df_Total[\"numorden\"] \n",
    "ordenes_conver_nueva =[]\n",
    "for elemento in ordenes_convert:\n",
    "    elemento = str(elemento)\n",
    "    ordenes_conver_nueva.append(elemento)\n",
    "    \n",
    "df_Total[\"numorden\"] = ordenes_conver_nueva\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "537df668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\276201073.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Total_Domi[\"numorden\"] = recorte\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\276201073.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Total_OMS.loc[df_Total_OMS[\"numorden\"].str.contains(\"CO1\"),\"Marcacion_Real\"] = \"OMS - Ecomm\"\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\276201073.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Total_OMS.loc[df_Total_OMS[\"numorden\"].str.contains(\"COCC\"),\"Marcacion_Real\"] = \"OMS - Call\"\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\276201073.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Total_OMS.loc[df_Total_OMS[\"numorden\"].str.contains(\"Y10\"),\"Marcacion_Real\"] = \"OMS - Dev\"\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\276201073.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Total_Traslado[\"numorden\"] = traslado_nuevo\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\276201073.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Total_Mostrador[\"numorden\"] = nuevo_numorden\n"
     ]
    }
   ],
   "source": [
    "df_Total_OMS = df_Total.loc[(df_Total[\"numorden\"].str.contains(\"CO1\"))|(df_Total[\"numorden\"].str.contains(\"COCC\")) |(df_Total[\"numorden\"].str.contains(\"Y10\"))]\n",
    "df_Total_Domi = df_Total.loc[(~df_Total[\"numorden\"].str.contains('CO|Y1',regex = True))&(df_Total[\"numorden\"].str.contains('102|000102',regex=True))]\n",
    "df_Total_Traslado = df_Total.loc[(df_Total[\"numorden\"].str.contains(\"SMT\"))|(df_Total[\"numorden\"].str.contains(\"smt\"))]\n",
    "\n",
    "recorte = []\n",
    "ordenes =df_Total_Domi[\"numorden\"]\n",
    "for orden in ordenes:\n",
    "    orden = orden[orden.find(\"1\"):20]\n",
    "    orden = orden[0:9]\n",
    "    recorte.append(orden)\n",
    "df_Total_Domi[\"numorden\"] = recorte\n",
    "\n",
    "\n",
    "Domi_pedido = Domifacil[\"pedido\"]\n",
    "pedido2= []\n",
    "for pedido in Domi_pedido:\n",
    "    pedido = str(pedido)\n",
    "    pedido2.append(pedido)\n",
    "Domifacil[\"pedido\"] = pedido2\n",
    "\n",
    "df_Total_Domi = pd.merge(df_Total_Domi,Domifacil,left_on=\"numorden\",right_on=\"pedido\",how = \"left\")\n",
    "\n",
    "df_Total_Domi = df_Total_Domi[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado','pedido']]\n",
    "df_Total_Domi.loc[~df_Total_Domi.pedido.isnull(),\"Marcacion_Real\"] = \"Pedido Call Center\"\n",
    "df_Total_Domi.loc[df_Total_Domi.pedido.isnull(),\"Marcacion_Real\"] = \"Sin Clasificar\"\n",
    " \n",
    "df_Total_OMS.loc[df_Total_OMS[\"numorden\"].str.contains(\"CO1\"),\"Marcacion_Real\"] = \"OMS - Ecomm\"\n",
    "df_Total_OMS.loc[df_Total_OMS[\"numorden\"].str.contains(\"COCC\"),\"Marcacion_Real\"] = \"OMS - Call\"\n",
    "df_Total_OMS.loc[df_Total_OMS[\"numorden\"].str.contains(\"Y10\"),\"Marcacion_Real\"] = \"OMS - Dev\"\n",
    "#############################################################################################33333\n",
    "Traslados_Bopos = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Traslados.xlsx\")\n",
    "\n",
    "traslado = df_Total_Traslado[\"numorden\"]\n",
    "traslado_nuevo = []\n",
    "for solicitud in traslado:\n",
    "    solicitud = str(solicitud)\n",
    "    solicitud=solicitud.replace(\"smt\",\"SMT\")\n",
    "    solicitud=solicitud.replace(\"-\",\"\")\n",
    "    solicitud=solicitud.replace(\" \",\"\")\n",
    "    solicitud=solicitud.replace(\"/\",\"\")\n",
    "    solicitud=solicitud.replace(\"_\",\"\")\n",
    "    traslado_nuevo.append(solicitud)\n",
    "    \n",
    "df_Total_Traslado[\"numorden\"] = traslado_nuevo\n",
    "\n",
    "df_Total_Traslado = pd.merge(df_Total_Traslado,Traslados_Bopos,left_on=\"numorden\",right_on=\"Documento Solicitud\",how = \"left\")\n",
    "\n",
    "df_Total_Traslado = df_Total_Traslado[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado','Documento Solicitud']]\n",
    "\n",
    "df_Total_Traslado.loc[df_Total_Traslado[\"Documento Solicitud\"].isnull(),\"Marcacion_Real\"] = \"Sin Clasificar - Traslado\"\n",
    "df_Total_Traslado.loc[~df_Total_Traslado[\"Documento Solicitud\"].isnull(),\"Marcacion_Real\"] = \"Traslado\"\n",
    "\n",
    "df_Total_Domi = df_Total_Domi[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']]\n",
    "df_Total_OMS = df_Total_OMS[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']]\n",
    "df_Total_Traslado = df_Total_Traslado[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']]\n",
    "\n",
    "df_Total_Cruzados = pd.concat([df_Total_Domi,df_Total_OMS,df_Total_Traslado],axis=0)\n",
    "#############################################################################################################\n",
    "\n",
    "df_Total = pd.merge(df_Total,df_Total_Cruzados,left_on=\"uuid\",right_on=\"uuid\",how = \"left\")\n",
    "\n",
    "df_Total = df_Total[['uuid','fecha_inicio_x','cant_paradas_x','distancia_km_x','Finalizado_Fallido_x','Tipo_Fallido_x','descripcion_x','iniciado_x','asignado_x','llego_punto_x','salio_punto_x','llego_cliente_x','finalizado_x','numorden_x','cliente_final_tipo_pago_x','ID_Origen_x','Marcacion_Real_y','Valor_con_Descuentos_x','ID_Solicitante_x','Proveedor_x','Estado_x']]\n",
    "df_Total.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado']\n",
    "\n",
    "\n",
    "df_Total_Mostrador = df_Total[df_Total.Marcacion_Real.isnull()]\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "Mostrador = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Mostrador.xlsx\")\n",
    "\n",
    "facturas =Mostrador[\"NumeroTicket\"] \n",
    "factura_nuevo = []\n",
    "for elemento in facturas:\n",
    "    elemento = str(elemento)\n",
    "    factura_nuevo.append(elemento)\n",
    "Mostrador[\"NumeroTicket\"] = factura_nuevo\n",
    "\n",
    "tickets = df_Total_Mostrador[\"numorden\"]\n",
    "nuevo_numorden = []\n",
    "\n",
    "for numorden in tickets:\n",
    "    numorden = str(numorden)\n",
    "    numorden = numorden.replace(\"-\",\"\")\n",
    "    numorden = numorden.replace(\" \",\"\")\n",
    "    numorden = numorden.replace(\"_\",\"\")\n",
    "    numorden = numorden.replace(\"/\",\"\")\n",
    "    nuevo_numorden.append(numorden)\n",
    "df_Total_Mostrador[\"numorden\"] = nuevo_numorden\n",
    "\n",
    "df_Total_Mostrador = pd.merge(df_Total_Mostrador,Mostrador, left_on = \"numorden\",right_on=\"NumeroTicket\",how=\"left\")\n",
    "\n",
    "df_Total_Mostrador = df_Total_Mostrador[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado_Fallido','Tipo_Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','ID_Origen','Marcacion_Real','Valor_con_Descuentos','ID_Solicitante','Proveedor','Estado','Canal']]\n",
    "\n",
    "df_Total_Mostrador.loc[df_Total_Mostrador.Canal.isnull(),\"Marcacion_Real\"] = \"Sin Clasificar\"\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "for i in range(0,len(df_Total_Mostrador)):\n",
    "    if df_Total_Mostrador.iloc[i,16] != \"Sin Clasificar\":\n",
    "            df_Total_Mostrador.iloc[i,16] = df_Total_Mostrador.iloc[i,21]\n",
    "    else: df_Total_Mostrador.iloc[i,16] = df_Total_Mostrador.iloc[i,16]\n",
    "        \n",
    "        \n",
    "df_Total_Mostrador.drop([\"Canal\"],axis=1,inplace = True)\n",
    "\n",
    "\n",
    "df_Total_final = pd.concat([df_Total_Cruzados,df_Total_Mostrador],axis=0)\n",
    "\n",
    "df_Total_final.to_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\validacion_marcacion.xlsx\")\n",
    "\n",
    "df_Total_final = df_Total_final[~df_Total_final.ID_Solicitante.isnull()]\n",
    "oms_busqueda = df_Total_final[df_Total_final.ID_Solicitante.isin([\"OMS\",\"oms\"]) & ~df_Total_final.Marcacion_Real.isin([\"Sin Clasificar\", \"Sin Clasificar - Traslado\"])]\n",
    "oms_busqueda = oms_busqueda[[\"uuid\",\"numorden\",\"Marcacion_Real\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "44347ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diciembre 2022(1).csv\n",
      "Diciembre 2022(2).csv\n",
      "Diciembre 2022(3).csv\n",
      "Diciembre 2022(4).csv\n",
      "Diciembre 2022(5).csv\n",
      "Diciembre 2022(6).csv\n",
      "Diciembre 2022(7).csv\n",
      "Noviembre 2022(1).csv\n",
      "Noviembre 2022(10).csv\n",
      "Noviembre 2022(2).csv\n",
      "Noviembre 2022(3).csv\n",
      "Noviembre 2022(4).csv\n",
      "Noviembre 2022(5).csv\n",
      "Noviembre 2022(6).csv\n",
      "Noviembre 2022(7).csv\n",
      "Noviembre 2022(8).csv\n",
      "Noviembre 2022(9).csv\n"
     ]
    }
   ],
   "source": [
    "resumen_total = pd.DataFrame(columns=[\"ORDER_NO\",\"SHIPNODE_KEY\"])\n",
    "for the_file in os.listdir(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Resumen_OMS\"):\n",
    "    archivo_subida = os.path.join(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Resumen_OMS\",the_file)             ###Importación del archivo de resumen\n",
    "    resumen_parcial=pd.read_csv(archivo_subida,sep=\",\")\n",
    "    columnas_resumen= [\"RN\",\"ORDER_HEADER_KEY\",\"ENTRY_TYPE\",\"ORDER_NO\",\"DOCUMENT_TYPE\",\"ORDER_DATE\",\"ORDER_TYPE\",\"ENTRY_TYPE2\",\"LEVEL_OF_SERVICE\",\"CUSTOMER_PHONE_NO\",\"EXTN_RUN_RUT_NIT\",\"ORIGINAL_TOTAL_AMOUNT\",\"ENTERPRISE_KEY\",\"PAYMENT_TYPE\",\"STATUS_NAME\",\"EXTN_ORG_REQ_SHIP_DATE\",\"STATUS_DATE\",\"EXTN_ET_FULFILMENT\",\"SHIPNODE_KEY\",\"BLANCOI\",\"BLANCOII\",\"BLANCOIII\",\"BLANCOIV\"]  \n",
    "    resumen_parcial.columns=columnas_resumen\n",
    "    resumen_parcial=resumen_parcial.drop(0,axis=0)\n",
    "    print(the_file)\n",
    "    resumen_parcial=resumen_parcial[[\"ORDER_NO\",\"SHIPNODE_KEY\"]]\n",
    "    resumen_total = pd.concat([resumen_total,resumen_parcial],axis=0)\n",
    "\n",
    "resumen_total = resumen_total[~resumen_total.SHIPNODE_KEY.isnull()]\n",
    "resumen_total = resumen_total.drop_duplicates(subset = ['ORDER_NO'])\n",
    "tiendas_oms = resumen_total[\"SHIPNODE_KEY\"]\n",
    "tiendas_no_pref =[]\n",
    "\n",
    "for elemento in tiendas_oms:\n",
    "    elemento = elemento.replace(\"COCV_\",\"\")\n",
    "    tiendas_no_pref.append(elemento)\n",
    "\n",
    "resumen_total[\"SHIPNODE_KEY\"] = tiendas_no_pref\n",
    "resumen_total[\"Origen\"] = \"RESUMEN\"\n",
    "\n",
    "transferencias_OMS = pd.read_csv(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\Transferencias_OMS\\Transferencias_Origen_Destino.csv\",sep = \",\")\n",
    "transferencias_OMS.columns = [\"RN\",\"EXTN_SO_NUMBER\",\"SHIPNODE_KEY\",\"RECEIVING_NODE\",\"ORDER_NO\",\"BLANCOI\"]\n",
    "transferencias_OMS  = transferencias_OMS.drop(0,axis =0)\n",
    "\n",
    "transferencias_OMS = transferencias_OMS[~transferencias_OMS.RECEIVING_NODE.isnull()]\n",
    "\n",
    "tiendas_oms_tr = transferencias_OMS[\"RECEIVING_NODE\"]\n",
    "tiendas_no_pref =[]\n",
    "\n",
    "for elemento in tiendas_oms_tr:\n",
    "    elemento = elemento.replace(\"COCV_\",\"\")\n",
    "    tiendas_no_pref.append(elemento)\n",
    "\n",
    "transferencias_OMS[\"RECEIVING_NODE\"] = tiendas_no_pref\n",
    "transferencias_OMS = transferencias_OMS[[\"RECEIVING_NODE\",\"ORDER_NO\"]]\n",
    "transferencias_OMS = transferencias_OMS.reindex(columns =[\"ORDER_NO\",\"RECEIVING_NODE\"])\n",
    "transferencias_OMS[\"Origen\"] = \"EARLY TRANSFER\"\n",
    "transferencias_OMS.columns = [\"ORDER_NO\",\"SHIPNODE_KEY\",\"Origen\"]\n",
    "\n",
    "OMS_unificado = pd.concat([resumen_total,transferencias_OMS],axis = 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3743febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\3491119546.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oms_busqueda_co[\"numorden\"] = ordenes_cruce\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\3491119546.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oms_busqueda_cocc[\"numorden\"] = ordenes_cruce\n",
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\3491119546.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oms_busqueda_y[\"numorden\"] = ordenes_cruce\n"
     ]
    }
   ],
   "source": [
    "oms_busqueda_co = oms_busqueda[(oms_busqueda.numorden.str.contains(\"CO1\"))] \n",
    "oms_busqueda_cocc = oms_busqueda[(oms_busqueda.numorden.str.contains(\"COCC\"))] \n",
    "oms_busqueda_y = oms_busqueda[(oms_busqueda.numorden.str.contains(\"Y10\"))] \n",
    "\n",
    "ordenes_oms = oms_busqueda_co[\"numorden\"]\n",
    "ordenes_cruce = []\n",
    "for elemento in ordenes_oms:\n",
    "    elemento = elemento[elemento.find(\"C\"):elemento.find(\"C\") + 10]\n",
    "    ordenes_cruce.append(elemento)\n",
    "    \n",
    "oms_busqueda_co[\"numorden\"] = ordenes_cruce\n",
    "\n",
    "\n",
    "ordenes_oms = oms_busqueda_cocc[\"numorden\"]\n",
    "ordenes_cruce = []\n",
    "for elemento in ordenes_oms:\n",
    "    elemento = elemento[elemento.find(\"C\"):elemento.find(\"C\")+12]\n",
    "    ordenes_cruce.append(elemento)\n",
    "    \n",
    "oms_busqueda_cocc[\"numorden\"] = ordenes_cruce \n",
    "\n",
    "\n",
    "ordenes_oms = oms_busqueda_y[\"numorden\"]\n",
    "ordenes_cruce = []\n",
    "for elemento in ordenes_oms:\n",
    "    elemento = elemento[elemento.find(\"Y\"):elemento.find(\"Y\") + 10]\n",
    "    ordenes_cruce.append(elemento)\n",
    "    \n",
    "oms_busqueda_y[\"numorden\"] = ordenes_cruce \n",
    "\n",
    "oms_busqueda_1 = pd.concat([oms_busqueda_co,oms_busqueda_cocc,oms_busqueda_y],axis=0)\n",
    "\n",
    "oms_busqueda_1 = pd.merge(oms_busqueda_1,OMS_unificado,left_on=\"numorden\",right_on =\"ORDER_NO\",how = \"left\")\n",
    "\n",
    " \n",
    "oms_busqueda_1.loc[(oms_busqueda_1[\"Origen\"]==\"EARLY TRANSFER\") & (oms_busqueda_1.numorden.str.contains(\"Y10\")),\"Marcacion_Real\"] == \"Transferencia OMS\"\n",
    "oms_busqueda_1.loc[(oms_busqueda_1[\"Origen\"]==\"RESUMEN\") & (oms_busqueda_1.numorden.str.contains(\"Y10\")),\"Marcacion_Real\"] == \"Dev - OMS\"\n",
    "oms_busqueda_1 = oms_busqueda_1[[\"uuid\",\"numorden\",\"Marcacion_Real\",\"SHIPNODE_KEY\"]]\n",
    "oms_busqueda_1.columns = [\"uuid\",\"numorden\",\"Marcacion_Real\",\"Tienda\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d8186933",
   "metadata": {},
   "outputs": [],
   "source": [
    "oms_busqueda_2 = oms_busqueda[(~oms_busqueda[\"numorden\"].str.contains('CO|Y1',regex = True))&(oms_busqueda[\"numorden\"].str.contains('102|000102',regex=True))]\n",
    "oms_busqueda_2 = pd.merge(oms_busqueda_2,Domifacil, left_on = \"numorden\",right_on =\"pedido\",how =\"left\")\n",
    "oms_busqueda_2 = oms_busqueda_2[[\"uuid\",\"numorden\",\"Marcacion_Real\",\"local_n\"]]\n",
    "oms_busqueda_2.columns =[\"uuid\",\"numorden\",\"Marcacion_Real\",\"Tienda\"]\n",
    "\n",
    "oms_busqueda_3 = oms_busqueda[(oms_busqueda[\"numorden\"].str.contains(\"SMT\"))|(oms_busqueda[\"numorden\"].str.contains(\"smt\"))]\n",
    "oms_busqueda_3 = pd.merge(oms_busqueda_3,Traslados_Bopos,left_on =\"numorden\",right_on=\"Documento Solicitud\", how = \"left\")\n",
    "oms_busqueda_3 = oms_busqueda_3[[\"uuid\",\"numorden\",\"Marcacion_Real\",\"Sucursal  Solitante\"]]\n",
    "oms_busqueda_3.columns = [\"uuid\",\"numorden\",\"Marcacion_Real\",\"Tienda\"]\n",
    "\n",
    "oms_busqueda_final = pd.concat([oms_busqueda_1,oms_busqueda_2,oms_busqueda_3],axis = 0)\n",
    "\n",
    "df_Total_final = pd.merge(df_Total_final,oms_busqueda_final, left_on =\"uuid\",right_on =\"uuid\",how = \"left\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5ca36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "solicitantes = df_Total_final[\"ID_Solicitante\"]\n",
    "i = 0\n",
    "for elemento in solicitantes:\n",
    "    if (str(elemento) == \"OMS\") | (str(elemento) == \"oms\"):\n",
    "        df_Total_final.iloc[i,18] = df_Total_final.iloc[i,23]\n",
    "        df_Total_final.iloc[i,16] = df_Total_final.iloc[i,22]\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e566e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoy = date.today()\n",
    "anio = hoy.year\n",
    "mes= hoy.month\n",
    "\n",
    "if mes<10 :\n",
    "    mes = '0' + str(mes)\n",
    "else: mes = str(mes)\n",
    "\n",
    "anio = str(anio)\n",
    "\n",
    "df_Total_final = df_Total_final[['uuid', 'fecha_inicio', 'cant_paradas', 'distancia_km',\n",
    "       'Finalizado_Fallido', 'Tipo_Fallido', 'descripcion', 'iniciado',\n",
    "       'asignado', 'llego_punto', 'salio_punto', 'llego_cliente', 'finalizado',\n",
    "       'numorden_x', 'cliente_final_tipo_pago', 'ID_Origen',\n",
    "       'Marcacion_Real_x', 'Valor_con_Descuentos', 'ID_Solicitante',\n",
    "       'Proveedor', 'Estado']]\n",
    "\n",
    "\n",
    "df_Total_final = df_Total_final.drop_duplicates(subset =\"uuid\" )\n",
    "\n",
    "df_Total_final.to_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\TotalCruceMostrador.xlsx\",index=False)\n",
    "\n",
    "df_Total_final = df_Total_final[~df_Total_final.ID_Solicitante.isnull()]\n",
    "df_Total_final = df_Total_final[df_Total_final[\"ID_Solicitante\"]!=\" \"]\n",
    "#df_Total_final[\"ID_Solicitante\"] = pd.to_numeric(df_Total_final[\"ID_Solicitante\"],downcast =\"integer\")\n",
    "\n",
    "\n",
    "df_Total_final.columns = ['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante','Proveedor','Estado']\n",
    "\n",
    "\n",
    "df_Total_cancelados = df_Total_final[df_Total_final.Estado.isin([\"CANCELACION\",\"Cancelado\"])]\n",
    "df_Total_cancelados = df_Total_cancelados[['uuid','fecha_inicio','numorden','ID Solicitante','Proveedor']]\n",
    "\n",
    "nombre_archivo = anio + mes + \" Cancelados.xlsx\"\n",
    "ruta = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Cancelados\",nombre_archivo)\n",
    "df_Total_cancelados.to_excel(ruta,index=False)\n",
    "\n",
    "df_Total_final = df_Total_final[df_Total_final.Estado.isin([\"CERRADO CON NOVEDAD\",\"Devuelta\",\"Devuelto\",\"ENTREGADO\",\"Exitosa\",\"Finalizado\"])] \n",
    "\n",
    "\n",
    "df_MU_total  = df_Total_final[df_Total_final[\"Proveedor\"] == \"MU\"]\n",
    "df_MU_total = df_MU_total[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante']]\n",
    "\n",
    "df_QuickGo_total  = df_Total_final[df_Total_final[\"Proveedor\"] == \"Quick Go\"]\n",
    "df_QuickGo_total = df_QuickGo_total[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante']]\n",
    "\n",
    "df_QuickHelp_total  = df_Total_final[df_Total_final[\"Proveedor\"] == \"Quick Help\"]\n",
    "df_QuickHelp_total= df_QuickHelp_total[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante']]\n",
    "\n",
    "\n",
    "df_Pibox_total  = df_Total_final[df_Total_final[\"Proveedor\"] == \"Pibox\"]\n",
    "df_Pibox_total= df_Pibox_total[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante']]\n",
    "\n",
    "df_Oficios_total  = df_Total_final[df_Total_final[\"Proveedor\"] == \"Oficios\"]\n",
    "df_Oficios_total= df_Oficios_total[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante']]\n",
    "\n",
    "\n",
    "df_Servicourier_total  = df_Total_final[df_Total_final[\"Proveedor\"] == \"Servicourier\"]\n",
    "df_Servicourier_total= df_Servicourier_total[['uuid','fecha_inicio','cant_paradas','distancia_km','Finalizado Fallido','Tipo Fallido','descripcion','iniciado','asignado','llego_punto','salio_punto','llego_cliente','finalizado','numorden','cliente_final_tipo_pago','2. ID Origen','16. Marcación Real','Valor con Descuentos','ID Solicitante']]\n",
    "\n",
    "nombre_archivo = anio + mes + \" Consolidado MU.xlsx\"\n",
    "ruta  = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Mensajeros Urbanos\\ConsolidadoServMU\",nombre_archivo)\n",
    "df_MU_total.to_excel(ruta,index=False,sheet_name =\"Hoja1\")\n",
    "\n",
    "nombre_archivo = anio + mes + \" Consolidado Quick Go.xlsx\"\n",
    "ruta  = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Quick\\Quick Go\",nombre_archivo)\n",
    "df_QuickGo_total.to_excel(ruta,index=False,sheet_name=\"Plano Quick Go\")\n",
    "\n",
    "nombre_archivo = anio + mes + \" Consolidado Quick.xlsx\"\n",
    "ruta  = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Quick\\ConsolidadoServQuick\",nombre_archivo)\n",
    "df_QuickHelp_total.to_excel(ruta,index=False, sheet_name = \"Hoja1\")\n",
    "\n",
    "nombre_archivo = anio + mes + \" Consolidado Picap.xlsx\"\n",
    "ruta  = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Picap\\Consolidado Servicios Picap\",nombre_archivo)\n",
    "df_Pibox_total.to_excel(ruta,index=False, sheet_name=\"Hoja1\")\n",
    "\n",
    "nombre_archivo = anio + mes + \" Consolidado Oficios.xlsx\"\n",
    "ruta  = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Oficios\\ConsolidadoServOficios\",nombre_archivo)\n",
    "df_Oficios_total.to_excel(ruta,index=False,sheet_name=\"Hoja1\")\n",
    "\n",
    "nombre_archivo = anio + mes + \" Consolidado Servicourier.xlsx\"\n",
    "ruta  = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Servicourier\\ConsolidadoServSC\",nombre_archivo)\n",
    "df_Servicourier_total.to_excel(ruta,index=False,sheet_name = \"Hoja1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066ec04",
   "metadata": {},
   "source": [
    "### Actualización venta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d81fef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa\n",
      "Info del servidor:  5.7.21-log\n"
     ]
    }
   ],
   "source": [
    "dia = date.today()\n",
    "dia = dia.day\n",
    "dia= dia - 1 \n",
    "\n",
    "\n",
    "try: \n",
    "    conexion = mysql.connector.connect(\n",
    "        host=\"172.18.50.54\",\n",
    "        port=3306,\n",
    "        user=\"operaciones\",\n",
    "        password=\"operaciones3\",\n",
    "        db=\"ventas\"\n",
    "    \n",
    "    )\n",
    "    \n",
    "    if conexion.is_connected(): \n",
    "        print(\"Conexión exitosa\")\n",
    "        infoServer = conexion.get_server_info()\n",
    "        print(\"Info del servidor: \", infoServer)\n",
    "        \n",
    "        cursor=conexion.cursor()\n",
    "        cursor.execute(\"SELECT Canal, Año, Mes, CodArticulo, Actividad, Dia, NumeroTicket, Sucursal, Venta, Clasifica1, periodo FROM ventasdiario_c WHERE periodo in ('202212') and Clasifica1 not in ('Droguería','Droguerias','Droguerías');\")\n",
    "        data = cursor.fetchall()\n",
    "        venta_diaria=pd.DataFrame(data)\n",
    "        venta_diaria.columns= cursor.column_names\n",
    "        \n",
    "except Error as ex:\n",
    "    print(\"Error durante conexión:\", ex)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8ce1b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.montoya\\AppData\\Local\\Temp\\ipykernel_19380\\1746996406.py:3: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.\n",
      "  pivot_venta_ = pd.pivot_table(venta_diaria,index = [\"Año\",\"Mes\",\"Dia\",\"Sucursal\",\"Clasifica1\"],values = [\"Venta\",\"NumeroTicket\"],aggfunc = [\"sum\",\"count\"])\n"
     ]
    }
   ],
   "source": [
    "dia = 15\n",
    "venta_diaria = venta_diaria[venta_diaria[\"Dia\"] <= dia]\n",
    "pivot_venta_ = pd.pivot_table(venta_diaria,index = [\"Año\",\"Mes\",\"Dia\",\"Sucursal\",\"Clasifica1\"],values = [\"Venta\",\"NumeroTicket\"],aggfunc = [\"sum\",\"count\"])\n",
    "pivot_venta_[(\"count\", \"venta/trx\")] = pivot_venta_[(\"sum\", \"Venta\")] /  pivot_venta_[(\"count\", \"NumeroTicket\")]\n",
    "venta_table =pivot_venta_.reset_index()\n",
    "venta_table.columns = [\"Año\",\"Mes\",\"Dia\",\"Sucursal\",\"Clasifica1\",\"Venta\",\"trx\",\"Venta2\",\"Venta / trx\"]\n",
    "venta_table = venta_table[[\"Año\",\"Mes\",\"Dia\",\"Sucursal\",\"Clasifica1\",\"Venta\",\"trx\",\"Venta / trx\"]]\n",
    "\n",
    "etiqueta_mes = {\"Mes_etq\":{\"Ene\":1,\n",
    "                           \"Feb\":2,\n",
    "                           \"Mar\":3,\n",
    "                           \"Abr\":4,\n",
    "                           \"May\":5,\n",
    "                           \"Jun\":6,\n",
    "                           \"Jul\":7,\n",
    "                           \"Ago\":8,\n",
    "                           \"Sep\":9,\n",
    "                           \"Oct\":10,\n",
    "                           \"Nov\":11,\n",
    "                           \"Dic\":12}}\n",
    "    \n",
    "venta_table[\"Mes_num\"] = venta_table[\"Mes\"].map(etiqueta_mes[\"Mes_etq\"])\n",
    "\n",
    "fechas_venta_list = []\n",
    "for i in range(0,len(venta_table)):\n",
    "    fecha_venta =   datetime.datetime(venta_table.iloc[i,0],venta_table.iloc[i,8], venta_table.iloc[i,2])\n",
    "    fechas_venta_list.append(fecha_venta)\n",
    "\n",
    "venta_table[\"Fecha\"] = fechas_venta_list\n",
    "venta_table[\"Fecha\"] = pd.to_datetime(venta_table[\"Fecha\"],format=\"%d/%m/%Y\")\n",
    "\n",
    "venta_table[\"Sucursal\"] = pd.to_numeric(venta_table[\"Sucursal\"], downcast = \"integer\")\n",
    " \n",
    "nombre_archivo = anio + mes + \" VentaDiaria.xlsx\"\n",
    "ruta = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\Domifacil, Concentrador, Bopos, Ventas\\Venta Diaria\",nombre_archivo)\n",
    "\n",
    "venta_table = venta_table[[\"Año\",\"Mes\",\"Dia\",\"Sucursal\",\"Clasifica1\",\"Venta\",\"trx\",\"Venta / trx\",\"Fecha\"]]\n",
    "venta_table[\"Sucursal\"]  = pd.to_numeric(venta_table[\"Sucursal\"], downcast = \"integer\")\n",
    "venta_table.to_excel(ruta,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18312e",
   "metadata": {},
   "source": [
    "### Cobro de domicilios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b9d3bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT Sucursal, NumeroTicket, CodArticulo, Venta, Ano, Mes, Dia, clasifica FROM ventasdiariogeoposh where periodo in ('202212') and clasifica = 'OMS';\")\n",
    "data = cursor.fetchall()\n",
    "cobro_oms=pd.DataFrame(data)\n",
    "cobro_oms.columns= cursor.column_names\n",
    "\n",
    "cobro_oms = cobro_oms[cobro_oms[\"CodArticulo\"]==297540]\n",
    "cobro_oms =cobro_oms[['Sucursal','CodArticulo','Venta','Ano','Mes','Dia',\"clasifica\"]]\n",
    "\n",
    "cobro_oms[\"Mes_num\"] = cobro_oms[\"Mes\"].map(etiqueta_mes[\"Mes_etq\"])\n",
    "\n",
    "fechas_cobro_list = []\n",
    "for i in range(0,len(cobro_oms)):\n",
    "    fecha_venta2 =   datetime.datetime(cobro_oms.iloc[i,3],cobro_oms.iloc[i,7], cobro_oms.iloc[i,5])\n",
    "    fechas_cobro_list.append(fecha_venta2)\n",
    "\n",
    "cobro_oms[\"Fecha_linea\"] = fechas_cobro_list\n",
    "cobro_oms[\"Fecha_linea\"] = pd.to_datetime(cobro_oms[\"Fecha_linea\"],format=\"%d/%m/%Y\")\n",
    "\n",
    "cobro_oms = cobro_oms[['Sucursal',\"CodArticulo\",\"Venta\",\"clasifica\",\"Fecha_linea\"]]\n",
    "cobro_oms = cobro_oms.reindex(columns=[\"Fecha_linea\",\"Sucursal\",\"CodArticulo\",\"clasifica\",\"Venta\"])\n",
    "cobro_oms.columns = [\"Fecha_linea\",\"Sucursal\",\"Codigo\",\"Canal\",\"Valor\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76ffecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobro_domifacil = pd.read_excel(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\CobroDomicilios\\Sku_Domifacil.xlsx\")\n",
    "cobro_domifacil = cobro_domifacil[cobro_domifacil.SKU.isin([531595,531594,531543,122580])]\n",
    "cobro_domifacil[\"Canal\"] = \"Domifacil\"\n",
    "\n",
    "etiqueta_cobro_domi = {\"cobro_cod\":{531595:3000,\n",
    "                           531594:2500,\n",
    "                           531543:1900,\n",
    "                           122580:2500}}\n",
    "    \n",
    "cobro_domifacil[\"Valor\"] = cobro_domifacil[\"SKU\"].map(etiqueta_cobro_domi[\"cobro_cod\"])\n",
    "\n",
    "cobro_domifacil = cobro_domifacil[cobro_domifacil.Estado.isin([\"processed\",\"complete\",\"processed_modified\",\"in_street\"])]\n",
    "\n",
    "fechas_cobro =cobro_domifacil[\"Fecha creación\"]\n",
    "nuevas_fechas_cobro = []\n",
    "\n",
    "for elemento in fechas_cobro:\n",
    "    fecha_cobro_domi = datetime.datetime(elemento.year,elemento.month,elemento.day)\n",
    "    nuevas_fechas_cobro.append(fecha_cobro_domi)\n",
    "\n",
    "cobro_domifacil[\"Fecha_linea\"] = nuevas_fechas_cobro\n",
    "\n",
    "cobro_domifacil[\"Fecha_linea\"] = pd.to_datetime(cobro_domifacil[\"Fecha_linea\"],format = \"%d/%m/%Y\")\n",
    "cobro_domifacil = cobro_domifacil[[\"Código Local\",\"SKU\",\"Canal\",\"Valor\",\"Fecha_linea\"]]\n",
    "cobro_domifacil = cobro_domifacil.reindex(columns=[\"Fecha_linea\",\"Código Local\",\"SKU\",\"Canal\",\"Valor\"])\n",
    "cobro_domifacil.columns = [\"Fecha_linea\",\"Sucursal\",\"Codigo\",\"Canal\",\"Valor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "86c4483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobro_mostrador = pd.read_csv(r\"C:\\Users\\luis.montoya\\Downloads\\Mostrador\\CobroDomicilios\\Cobro Mostrador.csv\",sep=\",\")\n",
    "\n",
    "cobro_mostrador = cobro_mostrador[[\"Año\",\"Mes\",\"Día\",\"Código Sucursal\",\"Código Producto\",\"Valor Total Línea\"]]\n",
    "cobro_mostrador[\"Canal\"] = \"Mostrador\"\n",
    "cobro_mostrador.columns = [\"Año\",\"Mes\",\"Dia\",\"Sucursal\",\"Codigo\",\"Valor\",\"Canal\"]\n",
    "\n",
    "cobro_mostrador = cobro_mostrador[cobro_mostrador.Codigo.isin([531595,531594,531543,122580])]\n",
    "\n",
    "fecha_cobro_mostrador = []\n",
    "for i in range(0,len(cobro_mostrador)):\n",
    "    fecha_linea = datetime.datetime(cobro_mostrador.iloc[i,0],cobro_mostrador.iloc[i,1],cobro_mostrador.iloc[i,2])\n",
    "    fecha_cobro_mostrador.append(fecha_linea)\n",
    "\n",
    "cobro_mostrador[\"Fecha_linea\"] = fecha_cobro_mostrador\n",
    "cobro_mostrador[\"Fecha_linea\"] = pd.to_datetime(cobro_mostrador[\"Fecha_linea\"],format = \"%d/%m/%Y\")\n",
    "\n",
    "cobro_mostrador =cobro_mostrador[[\"Sucursal\",\"Codigo\",\"Valor\",\"Canal\",\"Fecha_linea\"]]\n",
    "cobro_mostrador = cobro_mostrador.reindex(columns=[\"Fecha_linea\",\"Sucursal\",\"Codigo\",\"Canal\",\"Valor\"])\n",
    "cobro_mostrador[\"Sucursal\"] = pd.to_numeric(cobro_mostrador[\"Sucursal\"],downcast = \"integer\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a58cdbfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'C:\\\\Users\\\\luis.montoya\\\\OneDrive - Grupo Socofar\\\\PowerBI - Última milla\\\\CobroDomicilios\\\\202212 CobroDomicilios.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [148]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m nombre_archivo \u001b[38;5;241m=\u001b[39m anio \u001b[38;5;241m+\u001b[39m mes \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m CobroDomicilios.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m ruta \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mluis.montoya\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Grupo Socofar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPowerBI - Última milla\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCobroDomicilios\u001b[39m\u001b[38;5;124m\"\u001b[39m,nombre_archivo)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mcobro_total\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHoja1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2361\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2363\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2364\u001b[0m     df,\n\u001b[0;32m   2365\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2372\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2373\u001b[0m )\n\u001b[1;32m-> 2374\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2376\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:918\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    914\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:205\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1313\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1310\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1311\u001b[0m )\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'C:\\\\Users\\\\luis.montoya\\\\OneDrive - Grupo Socofar\\\\PowerBI - Última milla\\\\CobroDomicilios\\\\202212 CobroDomicilios.xlsx'"
     ]
    }
   ],
   "source": [
    "cobro_total = pd.concat([cobro_oms,cobro_domifacil,cobro_mostrador],axis = 0 )\n",
    "dia_actual = date.today()\n",
    "fecha_compara = datetime.datetime(dia_actual.year,dia_actual.month,dia_actual.day)\n",
    "cobro_total=cobro_total[cobro_total[\"Fecha_linea\"]<fecha_compara]\n",
    "cobro_total[\"Sucursal\"] = pd.to_numeric(cobro_total[\"Sucursal\"],downcast=\"integer\")\n",
    "\n",
    "nombre_archivo = anio + mes + \" CobroDomicilios.xlsx\"\n",
    "ruta = os.path.join(r\"C:\\Users\\luis.montoya\\OneDrive - Grupo Socofar\\PowerBI - Última milla\\CobroDomicilios\",nombre_archivo)\n",
    "cobro_total.to_excel(ruta,index=False,sheet_name = \"Hoja1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c51e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
